
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>Xu Tang&#39;s Homepages</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Xu Tang">
    

    
    <meta name="description" content="A paper a day keeps the PHD on">
<meta property="og:type" content="website">
<meta property="og:title" content="Xu Tang's Homepages">
<meta property="og:url" content="http://takecareofbigboss.github.io/index.html">
<meta property="og:site_name" content="Xu Tang's Homepages">
<meta property="og:description" content="A paper a day keeps the PHD on">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Xu Tang's Homepages">
<meta name="twitter:description" content="A paper a day keeps the PHD on">

    
    <link rel="alternative" href="/atom.xml" title="Xu Tang&#39;s Homepages" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Xu Tang&#39;s Homepages" title="Xu Tang&#39;s Homepages"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Xu Tang&#39;s Homepages">Xu Tang&#39;s Homepages</a></h1>
				<h2 class="blog-motto">Computer Vision&amp;Deep Learning&amp;Object Detection&amp;Zero-shot Learning</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜單">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/Contact-Me">Contact-Me</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:takecareofbigboss.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand poster" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/06/08/clustering-algorithm/" title="Clustering Algorithm" itemprop="url">Clustering Algorithm</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xu Tang" target="_blank" itemprop="author">Xu Tang</a>
		
  <p class="article-time">
    <time datetime="2015-06-08T08:25:06.000Z" itemprop="datePublished"> 發表於 2015-06-08</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="Clustering_Algorithm">Clustering Algorithm</h2><p>这篇博文解决了马毅老师《GPCA》新书中第四章的下面的问题：<br><img src="http://pfile.cn/23uzs3" alt=""><br><img src="http://pfile.cn/podbpw" alt=""></p>
<p>我把实现如下算法的几个都放在了自己的github主页：<a href="https://github.com/takecareofbigboss/clustering" target="_blank" rel="external">代码链接下载地址</a><br>函数解释文档<a href="https://github.com/takecareofbigboss/clustering/blob/master/README.md" target="_blank" rel="external">解释文档链接地址</a></p>
<h3 id="Laplacian_Eigenmaps_(LE)">Laplacian Eigenmaps (LE)</h3><p>&emsp;&emsp;LE算法的思路就是局部点之间的距离保持不变，进而使投影之后的结果也是保举的，和LPP的思路类似。其优化目标如下：<br><img src="http://pfile.cn/2ybdjb" alt=""></p>
<p>&emsp;&emsp;而对于W公式的构造有三种方法：<br>&emsp;&emsp;&emsp;&emsp;K-NN affinity:对于N*N的W矩阵，设置某个点i与其他所有的N个点中距离最小的K个点$W_{ij}$设置为1，其余点设置为0；<br>&emsp;&emsp;&emsp;&emsp;Gaussian affinity: $w_{ij}=exp(-||x_i-x_j||_2^2/2\theta ^2)$,并且$\theta$通常设置为1.0；<br>&emsp;&emsp;&emsp;&emsp;$\epsilon$-neighborhood:就是将距离小于$\epsilon$的$W_{ij}$设置为1，其余的设置为0；</p>
<p>&emsp;&emsp;我们如何分析这个优化问题呢？可以通过以下变形得知：<br><img src="http://pfile.cn/dsnnl0" alt=""><br>&emsp;&emsp;即最小化问题变成(约束条件由马毅老师的handnotes可知)：<br><img src="http://pfile.cn/kmtktc" alt=""><br>&emsp;&emsp;将优化问题改写成为拉格朗日函数：<br><img src="http://pfile.cn/c699cm" alt=""><br>&emsp;&emsp;经过求解可知，$YL=\Lambda YD$,进而推出$YLY^T=\Lambda YDY^T=\Lambda$,所以最优化的解变为$trace(YLY^T)=trace(\Lambda)$。这就是为什么算法流程图里面是求（L,D）的最小的d个特征值对应的特征向量。</p>
<h4 id="算法流程图：">算法流程图：</h4><p><img src="http://pfile.cn/oth20f" alt=""></p>
<h3 id="K-means_Clustering">K-means Clustering</h3><p>&emsp;&emsp;K-means算法的思路就是通过最小化所有数据点到离他最近的聚类中心的距离之和，并通过这个来估计聚类中心，并进行聚类。其优化目标如下：<br><img src="http://pfile.cn/5p5gq7" alt=""><br>&emsp;&emsp;其中，当数据点j的最近的聚类中心点i时，$W_{ij}=1$，其他的为0。$u_i$为聚类中心。</p>
<h4 id="算法流程图：-1">算法流程图：</h4><p><img src="http://pfile.cn/2o4asx" alt=""></p>
<h3 id="Spectral_Clustering">Spectral Clustering</h3><p>&emsp;&emsp;谱聚类的算法实际上就是基于图论的聚类方法，学习一个合适的非线性的映射，使得映射后的数据点可用k-means进行更好的分类。<br><img src="http://pfile.cn/ng0fay" alt=""><br>&emsp;&emsp;对于每一个connected graph，我们都可以写出一个如下的表达式，这也是使得这n个graph聚类的思路。因此我们要找到n个使得$LX=0X$的特征向量。但是实际中，需要找到n个最小的特征值对应的特征向量。</p>
<h4 id="算法流程图：-2">算法流程图：</h4><p><img src="http://pfile.cn/bixzt0" alt=""></p>
<h4 id="MinCut问题：">MinCut问题：</h4><p>&emsp;&emsp;实际上，n个connected graphs之间，也有极其小的连接，因此我们还需要度量不同subgraph之间的连接。优化目标如下：<br><img src="http://pfile.cn/jj731m" alt=""><br>&emsp;&emsp;因此，优化目标可以改写成：<br><img src="http://pfile.cn/8jkr0h" alt=""></p>
<h4 id="RatioCue问题：">RatioCue问题：</h4><p>&emsp;&emsp;但是我们会发现这样的优化目标最后会导致每一个数据点成了一个subgraph，因此我们需要加一个约束项使得这种情况不会发生。<br><img src="http://pfile.cn/rvm6zk" alt=""><br><img src="http://pfile.cn/ualv9r" alt=""><br>&emsp;&emsp;其中：<br><img src="http://pfile.cn/zprrrk" alt=""><br><img src="http://pfile.cn/syvb6a" alt=""><br>&emsp;&emsp;因此最终的优化问题又变成了：<br><img src="http://pfile.cn/yhc0a3" alt=""></p>
<h3 id="Normalized_Cut_&amp;_Normalized_Spectral_Clustering">Normalized Cut &amp; Normalized Spectral Clustering</h3><p><img src="http://pfile.cn/y937u4" alt=""></p>
<p>&emsp;&emsp;用拉格朗日解最后的方程得到$Lf=\lambda Df$,这是一个广义特征值问题，因此我们求这个表达式最小的n个广义特征值对应的广义特征向量。这是NCut问题的解法。<br>&emsp;&emsp;另一种解法是令$T=D^{1/2}F$,因此优化问题变成了解以下目标函数：<br><img src="http://pfile.cn/2w9hqh" alt=""><br>&emsp;&emsp;即求$D^{-1/2}LD^{-1/2}$的最小的n个特征值对应的特征向量问题。</p>
<h4 id="算法流程图：-3">算法流程图：</h4><h5 id="Normalized_Cut：">Normalized Cut：</h5><p><img src="http://pfile.cn/669c1m" alt=""></p>
<h5 id="Normalized_Spectral_Clustering:">Normalized Spectral Clustering:</h5><p><img src="http://pfile.cn/aj35sd" alt=""></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/06/08/clustering-algorithm/#comments" class="ds-thread-count comments-count-link" data-thread-key="2015/06/08/clustering-algorithm/" data-count-type="comments">&nbsp;</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand poster" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/06/08/how-to-use-github-blog/" title="how to use github blog" itemprop="url">how to use github blog</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xu Tang" target="_blank" itemprop="author">Xu Tang</a>
		
  <p class="article-time">
    <time datetime="2015-06-08T08:11:04.000Z" itemprop="datePublished"> 發表於 2015-06-08</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="hexo教程">hexo教程</h1><p>hexo new page “about”  新建一个about导航<br>INFO  Created: c:\Learning Files\github\tangxu\source\contact\index.md</p>
<p>hexo new post “mingzi” 新建一个mingzi的post来发表文章<br>INFO  Created: c:\Learning Files\github\tangxu\source_posts\post.md</p>
<p>![] ( 图片链接地址 )  在markdown中插入图片信息</p>
<p>&amp;emsp ; &amp; emsp;表示首行缩进两个格子</p>
<p>hexo d -g #生成加部署<br>hexo s -g #预览加部署</p>
<h3 id="github如何上传自己的代码：">github如何上传自己的代码：</h3><p>…or create a new repository on the command line</p>
<p>echo # - &gt;&gt; README.md<br>git init<br>git add README.md<br>git commit -m “first commit”<br>%—————此步需要手动在github创建新的repository，比如clustering————-%<br>git remote add origin <a href="https://github.com/takecareofbigboss/clustering.git" target="_blank" rel="external">https://github.com/takecareofbigboss/clustering.git</a><br>git push -u origin master<br>…or push an existing repository from the command line</p>
<p>git remote add origin <a href="https://github.com/takecareofbigboss/clustering.git" target="_blank" rel="external">https://github.com/takecareofbigboss/clustering.git</a><br>git push -u origin master<br>…or import code from another repository</p>
<p>You can initialize this repository with code from a Subversion, Mercurial, or TFS project.</p>
<p>每次需要提交代码的文件，就用以下操作：<br>git add k_means.m<br>git add main.m<br>git commit -m “first commit”<br>git push -u origin master</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/06/08/how-to-use-github-blog/#comments" class="ds-thread-count comments-count-link" data-thread-key="2015/06/08/how-to-use-github-blog/" data-count-type="comments">&nbsp;</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand poster" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/05/28/latex-module/" title="Latex Module" itemprop="url">Latex Module</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xu Tang" target="_blank" itemprop="author">Xu Tang</a>
		
  <p class="article-time">
    <time datetime="2015-05-28T13:28:43.000Z" itemprop="datePublished"> 發表於 2015-05-28</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="latex_模板">latex 模板</h2><p>\documentclass{article}<br>\usepackage{amssymb}<br>\usepackage{mathrsfs}<br>\usepackage{ctex}  %用于插入中文字符<br>\usepackage{float}<br>\usepackage[version=3]{mhchem} % Package for chemical equation typesetting<br>\usepackage{siunitx} % Provides the \SI{}{} and \si{} command for typesetting SI units<br>\usepackage[colorlinks,linkcolor=red,anchorcolor=blue,citecolor=green]{hyperref}<br>\usepackage{graphicx} % Required for the inclusion of images<br>\usepackage{natbib} % Required to change bibliography style to APA<br>\usepackage{amsmath} % Required for some math elements<br>\usepackage{indentfirst}</p>
<p>\setlength\parindent{2em} % Removes all indentation from paragraphs</p>
<p>\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)</p>
<p>%\usepackage{times} % Uncomment to use the Times New Roman font</p>
<p>%————————————————————————————————————————————<br>%    DOCUMENT INFORMATION<br>%————————————————————————————————————————————</p>
<p>\title{Weekly Report} % Title</p>
<p>\author{Xu Tang} % Author name</p>
<p>\date{\today} % Date for the report</p>
<p>\begin{document}</p>
<p>\maketitle % Insert the title, author and date</p>
<p>你好</p>
<p>\end{document}</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/05/28/latex-module/#comments" class="ds-thread-count comments-count-link" data-thread-key="2015/05/28/latex-module/" data-count-type="comments">&nbsp;</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand poster" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/05/28/The-Derivation-about-CNN-and-Antoencoder/" title="The Derivation about CNN and Antoencoder" itemprop="url">The Derivation about CNN and Antoencoder</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xu Tang" target="_blank" itemprop="author">Xu Tang</a>
		
  <p class="article-time">
    <time datetime="2015-05-28T12:31:33.000Z" itemprop="datePublished"> 發表於 2015-05-28</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="公式推导">公式推导</h2><p>本人用latex写的关于CNN和autoencoder的推导，前向和反向传播的推导都有证明。<br>pdf下载地址<a href="http://pan.baidu.com/s/1sjHTfxb" target="_blank" rel="external">The Derivation about CNN and Antoencoder</a></p>
<p>&emsp;&emsp;The Derivation about Convolutional Neural Networks:<br><img src="http://pfile.cn/rbay6h" alt=""></p>
<p>&emsp;&emsp;The Derivation about Sparse AutoEncoder:<br><img src="http://pfile.cn/d71l4s" alt=""></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/05/28/The-Derivation-about-CNN-and-Antoencoder/#comments" class="ds-thread-count comments-count-link" data-thread-key="2015/05/28/The-Derivation-about-CNN-and-Antoencoder/" data-count-type="comments">&nbsp;</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/05/23/caffe-on-GPU-cluster/" title="Caffe on GPU Cluster" itemprop="url">Caffe on GPU Cluster</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xu Tang" target="_blank" itemprop="author">Xu Tang</a>
		
  <p class="article-time">
    <time datetime="2015-05-23T11:56:17.000Z" itemprop="datePublished"> 發表於 2015-05-23</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>FOR ALL SOFTWARE PACKAGE,<br>YOU CAN GOOGLE IT AND DOWNLOAD FROM CORRESPONDING WEBSITE.</p>
<h2 id="Clone_the_caffe">Clone the caffe</h2><pre><code>git clone <span class="string">https:</span><span class="comment">//github.com/BVLC/caffe.git</span>
</code></pre><p>Before start this tutorial, you should first install python on cpu clusters</p>
<h4 id="Install_python">Install python</h4><pre><code>cd python2.<span class="number">7.9</span>
.<span class="regexp">/configure --prefix=/</span>str<span class="regexp">/users/</span>tangxu<span class="regexp">/local/</span> --enable-shared
make
make install
</code></pre><h3 id="Attention:">Attention:</h3><p>&emsp;&emsp;All the path /home/YOURNAME/local should be changed to /str/users/tangxu/local/ if you want to install it on the cpu clusters.<br>&emsp;&emsp;All the path /str/users/tangxu/local/ should be changed to /home/YOURNAME/local if you want to install it on the gpu server.</p>
<h2 id="-bashrc_file_setting">.bashrc file setting</h2><p>vim .bashrc</p>
<p>export PATH=/str/users/tangxu/local/bin:$PATH<br>export LD_LIBRARY_PATH=/str/users/tangxu/local/lib:$LD_LIBRARY_PATH</p>
<p>export PKG_CONFIG_PATH=/str/users/tangxu/local/lib/pkgconfig:$PKG_CONFIG_PATH<br>export PATH=/usr/local/cuda-7.0/bin:$PATH<br>export LD_LIBRARY_PATH=/usr/local/cuda-7.0/lib64:$LD_LIBRARY_PATH<br>PATH=/str/users/tangxu/local/include:/usr/include:/usr/local/include:$C_INCLUDE_PATH<br>PATH=/str/users/tangxu/local/include:/usr/include:/usr/local/include:$CPLUS_INCLUDE_PATH<br>export LD_LIBRARY_PATH=/opt/intel/lib/intel64:/opt/intel/mkl/lib/intel64:$LD_LIBRARY_PATH<br>export PYTHONPATH=/str/users/tangxu/local/lib/python2.7/site-packages/</p>
<h2 id="Install_openblas">Install openblas</h2><pre><code>download openblas 
make <span class="variable">FC=</span>gfortran <span class="variable">NO_AFFINITY=</span><span class="number">1</span> <span class="variable">USE_OPENMP=</span><span class="number">1</span> <span class="variable">USE_LAPACK=</span><span class="number">1</span>
make <span class="variable">PREFIX=</span>/str/users/tangxu/local/ install
</code></pre><h2 id="Install_all_depend">Install all depend</h2><h3 id="Install_cmake">Install cmake</h3><pre><code>download cmake
./bootstrap --prefix=<span class="regexp">/str/users</span><span class="regexp">/tangxu/local</span>
make
make install
</code></pre><h3 id="Install_Protobuf">Install Protobuf</h3><pre><code>download protobuf 
tar zxvf protobuf<span class="class">.tar</span><span class="class">.gz</span>
cd protobuf
./configure --prefix=/str/users/tangxu/local
make
make install
</code></pre><h3 id="Install_snappy">Install snappy</h3><pre><code>download snappy
tar zxvf snappy<span class="class">.tar</span><span class="class">.gz</span>
cd snappyma
./configure --prefix=/str/users/tangxu/local
make
make install
</code></pre><h3 id="Install_leveldb">Install leveldb</h3><pre><code>download leveldb
tar zxvf leveldb.tar.gz
cd leveldb
make
cp -av libleveldb.* <span class="regexp">/str/u</span>sers<span class="regexp">/tangxu/</span>local<span class="regexp">/lib/</span>
cp -av <span class="keyword">include</span><span class="regexp">/leveldb /</span>str<span class="regexp">/users/</span>tangxu<span class="regexp">/local/i</span>nclude<span class="regexp">/</span>
</code></pre><h3 id="Install_OpenCV">Install OpenCV</h3><pre><code>download opencv
tar zxvf opencv.tar.gz
<span class="keyword">cd</span> opencv
<span class="keyword">mkdir</span> release &amp;&amp; <span class="keyword">cd</span> release
cmake -<span class="keyword">D</span> CMAKE_BUILD_TYPE=RELEASE -<span class="keyword">D</span> CMAKE_INSTALL_PREFIX=/str/users/tangxu/<span class="keyword">local</span> -<span class="keyword">D</span> CUDA_GENERATION=Kepler ..
make
make install
</code></pre><h3 id="Install_Boost">Install Boost</h3><pre><code>download boost
./<span class="keyword">bootstrap</span>.<span class="keyword">sh</span> --prefix=/str/users/tangxu/<span class="keyword">local</span>
./b2 -j 32
./b2 install
</code></pre><h3 id="Install_google-glog_[!!!NOT_EASY,_CONFLICT_WITH_THE_GFLAGS_INSTALLED_IN_/USR/LOCAL_BY_ROOT]">Install google-glog [!!!NOT EASY, CONFLICT WITH THE GFLAGS INSTALLED IN /USR/LOCAL BY ROOT]</h3><pre><code>download glog
tar zxvf glog.tar.gz
<span class="keyword">cd</span> glog
./configure --prefix=/str/users/tangxu/<span class="keyword">local</span>
make -<span class="literal">j</span>
make install
</code></pre><h3 id="Install_gflags">Install gflags</h3><pre><code>download gflags
<span class="keyword">cd</span> gflags
<span class="keyword">mkdir</span> build &amp;&amp; <span class="keyword">cd</span> build
CXXFLAGS=<span class="string">"-fPIC"</span> cmake -<span class="keyword">D</span> CMAKE_INSTALL_PREFIX=/str/users/tangxu/<span class="keyword">local</span> ..
make -<span class="literal">j</span>
make install
</code></pre><h3 id="Install_lmdb">Install lmdb</h3><pre><code>download lmdb
cd mdb/libraries/liblmdb
make
make prefix=/str/users/tangxu/local <span class="operator"><span class="keyword">install</span>
# man was <span class="keyword">not</span> <span class="keyword">found</span>, it does <span class="keyword">not</span> matter [you should <span class="keyword">add</span> the file <span class="keyword">local</span>/man/man1]</span>
</code></pre><h3 id="Install_hdf5">Install hdf5</h3><pre><code> download hdf5
tar zxvf hdf5.tar.gz
cd hdf5
<span class="keyword">.</span>/configure --prefix=/str/users/tangxu/local
make
make<span class="instruction"> check </span>               <span class="comment"># run test suite.</span>
make install
make<span class="instruction"> check-install </span>       <span class="comment"># verify installation.</span>
</code></pre><h3 id="Install_cuDNN">Install cuDNN</h3><pre><code>download cuDNN
*<span class="keyword">copy</span> <span class="keyword">the</span> cudnn lib <span class="keyword">and</span> head <span class="keyword">to</span> ~/<span class="keyword">local</span>/lib <span class="keyword">and</span> ~/<span class="keyword">local</span>/include
*<span class="keyword">or</span> you can download <span class="keyword">the</span> cudnn library <span class="keyword">from</span> website <span class="keyword">and</span> <span class="keyword">copy</span>
cp /path/<span class="keyword">to</span>/cudnn/*  /str/users/tangxu/<span class="keyword">local</span>/lib
cp /path/<span class="keyword">to</span>/cudnn/*  /str/users/tangxu/<span class="keyword">local</span>/include
</code></pre><h2 id="Add_the_path_int_~/-bashrc">Add the path int ~/.bashrc</h2><pre><code>vim ~/.bashrc
============[.bashrc]
// <span class="keyword">for</span> gpu
<span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda/bin:<span class="variable">$PATH</span>
<span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda/lib64:<span class="variable">$LD_LIBRARY_PATH</span>
// <span class="keyword">for</span> OpenBLAS
<span class="built_in">export</span> LD_LIBRARY_PATH=/data1/NLPRMNT/xxxxxxxxxx/<span class="built_in">local</span>/OpenBLAS/lib:<span class="variable">$LD_LIBRARY_PATH</span>
<span class="comment">#for ~/local </span>
<span class="built_in">export</span> LD_LIBRARY_PATH=/data1/NLPRMNT/xxxxxxxxxx/<span class="built_in">local</span>/lib:<span class="variable">$LD_LIBRARY_PATH</span>
<span class="built_in">export</span> PATH=/data1/NLPRMNT/xxxxxxxxxx/<span class="built_in">local</span>/bin:<span class="variable">$PATH</span>
// <span class="keyword">for</span> openMP
<span class="built_in">export</span> OMP_NUM_THREADS=<span class="number">20</span>
============
<span class="built_in">source</span> ~/.bashrc
</code></pre><h2 id="Compile_caffe">Compile caffe</h2><p>   *Edit the Makefile.config<br>   cp Makefile.config.example Makefile.config<br>   vim Makefile.config<br>       ============[Makefile.config]<br>       USE_CUDNN := 1<br>       CUDA_DIR := /usr/local/cuda<br>       BLAS := open<br>       BLAS_INCLUDE := /data1/NLPRMNT/xxxxxxxxxx/local/OpenBLAS/include<br>       BLAS_LIB := /data1/NLPRMNT/xxxxxxxxxx/local/OpenBLAS/lib<br>       INCLUDE_DIRS := /data1/NLPRMNT/xxxxxxxxxx/local/include<br>       LIBRARY_DIRS := /data1/NLPRMNT/xxxxxxxxxx/local/lib</p>
<pre><code><span class="header">#commit the python/matlab part
============</span>
</code></pre><p>   *make, the first two lines were run on login node<br>   make all -j8<br>   make test -j8<br>   make runtest -j8</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/05/23/caffe-on-GPU-cluster/#comments" class="ds-thread-count comments-count-link" data-thread-key="2015/05/23/caffe-on-GPU-cluster/" data-count-type="comments">&nbsp;</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/05/20/Yi-Ma-s-Sayings/" title="Yi Ma&#39;s Sayings" itemprop="url">Yi Ma&#39;s Sayings</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xu Tang" target="_blank" itemprop="author">Xu Tang</a>
		
  <p class="article-time">
    <time datetime="2015-05-20T09:48:51.000Z" itemprop="datePublished"> 發表於 2015-05-20</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="马毅教授科研经验语录：">马毅教授科研经验语录：</h2><h3 id="关于如何与学术界人交流与沟通：">关于如何与学术界人交流与沟通：</h3><p>&emsp;&emsp;把你的问题formulate清楚。经常有人问我要稀疏字典的code，发个邮件过来说：“诶，马老师，你的某篇论文我有点不太清楚，能不能把code发给我？”<br>&emsp;&emsp;“你连问题都没问清楚，我凭什么把我的code给你。”<br>&emsp;&emsp;在你提出问题的时候，要把你付出的努力，你做过什么说清楚。让人家看到你哪里努力了,让人家看到你都做了些什么，这样人家才清楚把他的代码share给你有没有意义。所以你们以后发邮件问作者的时候，一定要把你做过的东西说清楚，把你的问题定义清楚，这样人家才乐意去回复你。</p>
<h3 id="关于组会准备工作：">关于组会准备工作：</h3><p>&emsp;&emsp;以后每次工作都要准备好你的slides，不要等我问到你们的时候，什么都回答不上来。等到我什么都不问你了，也就不会care你了。所以要主动去问，遇到公式推不懂，把问题formulate清楚了告诉我。我会帮你解决的。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/05/20/Yi-Ma-s-Sayings/#comments" class="ds-thread-count comments-count-link" data-thread-key="2015/05/20/Yi-Ma-s-Sayings/" data-count-type="comments">&nbsp;</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/05/19/deep-learning/" title="Deep Learning for Object Detection and Segmentation" itemprop="url">Deep Learning for Object Detection and Segmentation</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xu Tang" target="_blank" itemprop="author">Xu Tang</a>
		
  <p class="article-time">
    <time datetime="2015-05-19T11:13:15.000Z" itemprop="datePublished"> 發表於 2015-05-19</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="slides下载链接地址"><a href="http://pan.baidu.com/s/1dDrSKW5" target="_blank" rel="external">slides下载链接地址</a></h2><p>&emsp;&emsp;这个slides是我和陈思秦在上海科技大学paper reading group组会上面做的presentation。slides中包括了object detection和segmentation的introduction，datasets，related work，evaluation metric以及novel models。其中models主要讲解经典的deep learning做object detection模型<a href="http://arxiv.org/pdf/1311.2524.pdf" target="_blank" rel="external">《Rich feature hierarchies for accurate object detection and semantic segmentation》</a>和deep learning做segmentation模型<a href="http://arxiv.org/pdf/1412.0774v1.pdf" target="_blank" rel="external">Feedforward semantic segmentation with zoom-out features</a>。</p>
<p>&emsp;&emsp;选取几页ppt截图如下：</p>
<h3 id="常用数据集：">常用数据集：</h3><p><img src="http://pfile.cn/2n3alp" alt=""><br><img src="http://pfile.cn/6s8rhu" alt=""><br><img src="http://pfile.cn/ifug7m" alt=""></p>
<h3 id="常用评判标准：">常用评判标准：</h3><p><img src="http://pfile.cn/93cezj" alt=""><br><img src="http://pfile.cn/33lsjt" alt=""><br><img src="http://pfile.cn/i7yhom" alt=""></p>
<h3 id="模型示例图：">模型示例图：</h3><p>hinton2012的经典CNN模型图示：<br><img src="http://pfile.cn/4ftzif" alt=""></p>
<p>RCNN模型图示：<br><img src="http://pfile.cn/gx1hdm" alt=""></p>
<p>segmentation模型图示：<br><img src="http://pfile.cn/o5t95v" alt=""></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/05/19/deep-learning/#comments" class="ds-thread-count comments-count-link" data-thread-key="2015/05/19/deep-learning/" data-count-type="comments">&nbsp;</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/05/11/RussianCube/" title="RussianCube" itemprop="url">RussianCube</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xu Tang" target="_blank" itemprop="author">Xu Tang</a>
		
  <p class="article-time">
    <time datetime="2015-05-11T13:32:58.000Z" itemprop="datePublished"> 發表於 2015-05-11</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="俄罗斯方块openGL程序：">俄罗斯方块openGL程序：</h2><p>使用本程序需要安装openGL库文件，具体安装教程请看<a href="http://www.cnblogs.com/Linkliu/articles/leanC.html" target="_blank" rel="external">链接</a>。</p>
<h2 id="俄罗斯方块程序声明：">俄罗斯方块程序声明：</h2><p>由于本程序选装用的是矩阵相乘进行旋转，因此个别地方会有bug。如果将程序改为直接列举出19种旋转的情况，这些bug会消除。另外，我在程序里面写了很多输出检测的调试代码，因此运行的时候，会有点卡。如果删除所有的命令行输出语句，程序几乎没有bug。</p>
<p>后期改进也没有什么问题，只不过由于课程比较紧，有很多论文需要看，所以不打算改进了。</p>
<h2 id="俄罗斯方块程序链接地址"><a href="https://github.com/takecareofbigboss/Russian_cube" target="_blank" rel="external">俄罗斯方块程序链接地址</a></h2>
        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/05/11/RussianCube/#comments" class="ds-thread-count comments-count-link" data-thread-key="2015/05/11/RussianCube/" data-count-type="comments">&nbsp;</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/05/10/VALSE2015/" title="VALSE2015" itemprop="url">VALSE2015</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xu Tang" target="_blank" itemprop="author">Xu Tang</a>
		
  <p class="article-time">
    <time datetime="2015-05-10T05:08:43.000Z" itemprop="datePublished"> 發表於 2015-05-10</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="5月8日至10日在成都参加了VALSE2015，VALSE是国内计算机视觉青年学者的盛会。大会程序安排_/_会议手册详细版">5月8日至10日在成都参加了<a href="http://www.uestcrobot.net/valse2015/" target="_blank" rel="external">VALSE2015</a>，VALSE是国内计算机视觉青年学者的盛会。<a href="http://www.uestcrobot.net/valse2015/programs.html" target="_blank" rel="external">大会程序安排</a> / <a href="http://www.uestcrobot.net/valse2015/doc/VALSE2015LongProgram.pdf" target="_blank" rel="external">会议手册详细版</a></h1><h2 id="5月8日活动：">5月8日活动：</h2><p>&emsp;&emsp;8日活动，王晓刚和王乃岩给了tutorial，是关于deep learning的经验指导，以及他们最近的工作。王晓刚主要是用deep learning做人脸，众所周知，CUHK在这方面做得很出色，特别是ILSVRC竞赛中获得了很好的成绩。关于王晓刚的slides，我看到了某位同学整理的<a href="http://pan.baidu.com/share/link?shareid=78745218&amp;uk=3976704611]" target="_blank" rel="external">PDF版本</a>, 我自己也整理了一份slides的拍照版公布在<a href="http://pan.baidu.com/share/link?shareid=135036996&amp;uk=3976704611" target="_blank" rel="external">百度网盘链接</a> 。王晓刚本人主页上也有公布<a href="http://www.ee.cuhk.edu.hk/~xgwang/talks/deeo_learning_icip2.pdf" target="_blank" rel="external">slides内容</a>。下面我简单的整理一下王晓刚给的talk的内容，王晓刚talk中谈到以下一些内容：<br>&emsp;&emsp;&emsp;&emsp;1)Overfitting:训练集很好，测试集很差的情况。<br>&emsp;&emsp;&emsp;&emsp;2）针对人脸识别中人脸数据集太规矩的情况，介绍了LFW数据集，并且讲了他们小组在这个数据集上面识别率的提高。<br>&emsp;&emsp;&emsp;&emsp;3）为什么DL取得成功。因为imagenet数据集的公布以及hinton2012结构的提出，还有evaluation task的提出。大数据才适合做deep learning，小数据及不适合做deep learning。特别是人与非人的问题，用深度学习去做会很难，因为神经网络面对非人的场景会confused。<br>&emsp;&emsp;&emsp;&emsp;4）总结了经典的深度学习模型：CNN，auto-encoder，deep belief net<br>&emsp;&emsp;&emsp;&emsp;5）为什么深度学习会work。首先是深度学习能够学习到比较好的feature，而且这些feature在CNN中是能够通过pool后，从小的pixel获得局部区域的信息的。而且深度比宽度更重要。<br>&emsp;&emsp;&emsp;&emsp;6）joint learning和separate learning的对比，同时简述了end-to-end的大趋势。同时也讲了他的work里面是如何用到joint learning的。<br>&emsp;&emsp;&emsp;&emsp;7）domain knowledge在深度神经网络里的利用。<br>&emsp;&emsp;&emsp;&emsp;8）花了很大功夫介绍DeepID到底学到了什么样的特征。<br>&emsp;&emsp;&emsp;&emsp;9）深度学习就是大数据的机器学习，特征学习，end-to-end以及上下文的学习。深度学习的表示是sparse，selective，robust的。</p>
<p>&emsp;&emsp;王乃岩博士的工作主要是tracking，他的slides的前半部分对我很有启发作用，他对神经网络的multi-level进行了分析。对于我这种深度学习的新手，很有效果。提出新模型的时候，可以借鉴王乃岩的工作。他的slides在<a href="http://winsty.net/miscellaneous.html?from=singlemessage&amp;isappinstalled=0" target="_blank" rel="external">此链接</a>可以找到。<br>&emsp;&emsp;王乃岩talk中的内容大概可以分为以下几点：<br>&emsp;&emsp;&emsp;&emsp;1）pixel labeling应用的几个场景以及问题。比如image segmentation、boundary detection、saliency detection、3D scene understanding。<br>&emsp;&emsp;&emsp;&emsp;2）王博士提到的最重要的DL里面的两个趋势是，end-to-end learning以及multi-level fusion的问题。对于我这种新手来说，这方面的指导是很重要的。关于end-to-end也就是把处理一类问题的几个步骤结合起来进行参数的优化，（比如说对于object detection问题，可以将提取特征、分类器等操作的参数一起优化。）具体可以参考一下图示：<br><img src="http://pfile.cn/gycl86" alt=""><br>&emsp;&emsp;&emsp;&emsp;而对于multi-level fusion，我可以用下面几张图展示一下：<br><img src="http://pfile.cn/pbkavq" alt=""><br><img src="http://pfile.cn/7cgq22" alt=""><br><img src="http://pfile.cn/ta16i3" alt=""><br><img src="http://pfile.cn/e4jnru" alt=""><br><img src="hhttp://pfile.cn/rtmq12" alt=""><br><img src="http://pfile.cn/byiyrh" alt=""><br><img src="http://pfile.cn/cfnjn8" alt=""><br><img src="http://pfile.cn/k0j74h" alt=""><br><img src="http://pfile.cn/advxxj" alt=""><br><img src="http://pfile.cn/bg8lki" alt=""><br>&emsp;&emsp;&emsp;&emsp;3)接下来，王乃岩博士讲了他的work：object detection，Image Caption Generation，Surface Normal Estimation，Visual Tracking以及用到的模型细节。</p>
<h2 id="5月9日活动：">5月9日活动：</h2><p>&emsp;&emsp;9日活动，周志华和王立威的工作都比较偏机器学习的理论，对于我这个深度学习方向的，我有很多东西都不是很懂。因此不列举出来了，不过周志华老师的ppt一般会在会议后给出链接，具体可以参考<a href="http://weibo.com/zhouzh2012" target="_blank" rel="external">周志华老师微博</a>。<br>&emsp;&emsp;王立威老师的talk内容大致为：证明margin这一机器学习经典结论并不完全正确，SVM性能并非仅由margin决定而与特征空间维数无关。具体的，我将证明一个基于与特征空间维数相关的margin上界。该上界一致紧于经典的维数无关margin上界；当特征空间维数是无穷大时，新上界等价于传统维数无关margin上界。这一margin理论表明，核方法为了提高margin而增加特征空间维数时，一定程度上付出了性能的代价。实验结果显示该理论对于SVM核函数的选择具有指导意义。<br>&emsp;&emsp;王瑞平的工作是我最近打算研究的视频里面的人脸识别，王瑞平老师也是山世光教授课题组的。他的talk内容是《Learning on Riemannian Manifold for Video-Based Face Recognition》。王瑞平老师talk的<a href="http://pan.baidu.com/share/link?shareid=2093229570&amp;uk=3976704611" target="_blank" rel="external">slides</a>可以参考这里。</p>
<p>&emsp;&emsp;比较有意思的是下午微软MSRA孙剑博士和百度IDL美国黄畅博士的talk。他们分别讲述了两个工业界巨头近期关于深度学习的工作。<br>&emsp;&emsp;&emsp;&emsp;MSRA孙剑老师的VALSE2015 slides首先讲述了deep learning的initialization algorithm，network designs，parametric neurons。其中初始化算法主要是讲设计一个好的算法来得到神经网络的初始化参数，网络设计主要是关于模型结构的讲解，最后一个孙剑博士主要讲了一下PReLu的performance的变化。然后讲了MSRA最近关于deep的很多工作，包括how-old.net、object detection中的SPP-net。<a href="http://pan.baidu.com/share/link?shareid=2251908627&amp;uk=3976704611" target="_blank" rel="external">slides网盘地址</a>。<br>&emsp;&emsp;&emsp;&emsp;百度IDL美国黄畅博士得slides讲述了IDL美国这两年的工作以及对deep learning未来发展趋势的预测、经验总结。百度的工作主要是OCR的end-to-end，人脸识别，face detection。<a href="http://pan.baidu.com/share/link?shareid=2335978996&amp;uk=3976704611" target="_blank" rel="external">slides网盘地址</a><br>&emsp;&emsp;&emsp;&emsp;黄畅博士总结的深度学习的经验是：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;1）数据扩充用来引入输入图片的低维度知识。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;2）结构化loss利用系统输出的高维度规则。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;3）稀疏参数和特征，变化size的卷积，多任务的joint学习，低秩的规则化都是有帮助的。<br>&emsp;&emsp;&emsp;&emsp;黄畅博士谈到的深度学习的未来是：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;1）大规模的weak、部分标注的数据。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;2）针对独立的任务设计整体的框架。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;3）early vision + high-level vision。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;4）硬件和传感器。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;5）sequential vs. concurrent。</p>
<p>&emsp;&emsp;&emsp;VALSE2015成都墙报poster环节，我拍了关于object detection，segmentation，image classification，distance metric learning，face recognition，tracking有关的所有poster。里面的poster都是ICCV/CVPR/TIP等顶级会议、期刊的论文。上传<a href="http://pan.baidu.com/share/link?shareid=2142101467&amp;uk=3976704611" target="_blank" rel="external">网盘地址</a>。</p>
<h2 id="VALSE2016在武汉。bid结果是VALSE2017厦门，VALSE2018大连。">VALSE2016在武汉。bid结果是VALSE2017厦门，VALSE2018大连。</h2><h2 id="5月10日活动：">5月10日活动：</h2><p>&emsp;&emsp;&emsp;&emsp;VALSE2015之Ladies in VALSE<br><img src="http://ww4.sinaimg.cn/bmiddle/6dd6ca05jw1erz1wxr69rj20hs0dcq3t.jpg" alt=""><br><img src="http://ww2.sinaimg.cn/bmiddle/6dd6ca05jw1erz1wy8zqrj20hs0dct9z.jpg" alt=""><br><img src="http://ww1.sinaimg.cn/bmiddle/6dd6ca05jw1erz1wwo7mrj20hs0dcdh1.jpg" alt=""></p>
<p>&emsp;&emsp;&emsp;&emsp;10日的活动比较无聊，所以不具体说了，放图：<br><img src="http://pfile.cn/rbsafa" alt=""><br><img src="http://pfile.cn/b277oe" alt=""></p>
<h1 id="最后放上颜水城老师和我的合照！！！">最后放上颜水城老师和我的合照！！！</h1><p><img src="http://ww1.sinaimg.cn/bmiddle/6dd6ca05jw1erxwq96ngmj20ku0rsjw9.jpg" alt=""></p>
<h1 id="再放上马毅老师的新书《Generalized_Principal_Component_Analysis》镇楼！！！欢迎大家购买马老师新书哦！！！">再放上马毅老师的新书《Generalized Principal Component Analysis》镇楼！！！欢迎大家购买马老师新书哦！！！</h1><p><img src="http://ww4.sinaimg.cn/bmiddle/6dd6ca05jw1erwoqslnrjj20hs0dcgn3.jpg" alt=""></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/05/10/VALSE2015/#comments" class="ds-thread-count comments-count-link" data-thread-key="2015/05/10/VALSE2015/" data-count-type="comments">&nbsp;</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/05/01/post/" title="《Zero-Shot Learning Through Cross-Modal Transfer》" itemprop="url">《Zero-Shot Learning Through Cross-Modal Transfer》</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xu Tang" target="_blank" itemprop="author">Xu Tang</a>
		
  <p class="article-time">
    <time datetime="2015-05-01T07:21:34.000Z" itemprop="datePublished"> 發表於 2015-05-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h2 id="《Zero-Shot_Learning_Through_Cross-Modal_Transfer》论文阅读理解">《Zero-Shot Learning Through Cross-Modal Transfer》论文阅读理解</h2><p>最近想了解下zero-shot learning的资料，于是看了篇andrew ng的论文，论文地址<a href="http://papers.nips.cc/paper/5027-zero-shot-learning-through-cross-modal-transfer.pdf">《Zero-Shot Learning Through Cross-Modal Transfer》</a>。由于我之前一直是研究的图像有关领域，所以对于我这种刚了解文本的菜鸟，要想更好的了解这篇文章，最好是提前了解什么是【<a href="http://pan.baidu.com/s/1dDAiQel">词向量</a>】,【<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.249.7180&amp;rep=rep1&amp;type=pdf">如何根据local，global的context提取词向量Improving Word Representations via Global Context and Multiple Word Prototypes</a>】，【<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Coates_485.pdf">如何提取图片的特征</a>】。基本上有了这些知识就不难看懂这篇论文。</p>
<h3 id="摘要：">摘要：</h3><p>&emsp;&emsp;本文旨在引入一个模型来识别图像，即便这个图像中有个别类的物体不在训练样本中。唯一关于未知类物体的先验知识来自无监督的文本语料库。我们的模型既能够在已有的训练样本类的测试中获得state-of-art的识别率，又能够在未知类作为测试样本时候获得不错的效果。首先，我们在语义空间使用异常值检测（将测试样本通过投影矩阵theta投影到一个space中），然后分别使用两个独立的识别模型。如果检测出来是已知类，则使用softmax分类器；如果检测出来是未知类，则使用等距高斯分布进行分类。</p>
<h3 id="Introduction：">Introduction：</h3><p>&emsp;&emsp;Zero-shot model能够预测已知和未知类的label。例如，从没看见过一张猫的图片，却可以决定这张test图片的label到底是一只猫，还是一个已知的训练样本中的类，比如狗或者马。这种模型基于两个主要的想法：<br>1、    图像通过神经网络模型学到的参数，被map到words的语义空间。<br>2、    模型合并异常值检测概率，用于决定一个新的图片是否在已知类的流形中。如果图片是已知类，则可以使用标准的分类器。否则，图片被分配到基于似然性的未知类中。</p>
<p><img src="http://ww3.sinaimg.cn/thumbnail/6dd6ca05gw1erosa5e2xmj20v60nen1l.jpg" alt=""></p>
<h3 id="Word_and_Image_Representations(单词和图像的表示)：">Word and Image Representations(单词和图像的表示)：</h3><p>&emsp;&emsp;单词被表示成分布特征的向量，我们使用<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.249.7180&amp;rep=rep1&amp;type=pdf">Huang[15]</a>的无监督模型来得到50维度的预训练的词向量，作为初始化的word vectors。<br>&emsp;&emsp;具体方法可以参见论文《Improving Word Representations via Global Context and Multiple Word Prototypes》。<br>&emsp;&emsp;想法很简单，就是结合local 和global context来学习一个更好的词向量（这种词向量很好的针对一词多义、同音异义的情况训练一个单词的不同的向量）。优化函数就是要最小化：<br><img src="http://ww4.sinaimg.cn/bmiddle/6dd6ca05gw1eros6t4ph1j20gg02xglx.jpg" alt=""><br>&emsp;&emsp;整个操作如下图所示：<br><img src="http://ww4.sinaimg.cn/bmiddle/6dd6ca05gw1eros6tx105j20ok0iejv3.jpg" alt=""><br>&emsp;&emsp;我们使用<a href="http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Coates_485.pdf">Coates[6]</a>的方法来提取原始图片中的F维度的图像特征。<br><img src="http://ww2.sinaimg.cn/bmiddle/6dd6ca05gw1eros6trsfmj20oj0iddlb.jpg" alt=""></p>
<h3 id="Projecting_Images_into_Semantic_Word_Spaces(把图片映射到语义词向量空间)：">Projecting Images into Semantic Word Spaces(把图片映射到语义词向量空间)：</h3><p>&emsp;&emsp;我们需要把图片映射到50-维度的词向量空间。我们的训练和测试实际上是把Cifar10数据库里面的一大部分类拿出来当做available training data，这一部分也叫做seen classes Y_s。极少部分类当做zero-shot classes（也就是训练样本中不出现的类），这部分叫做unseen classes Y_u。<br>&emsp;&emsp;本章主要是讲已知类的图片映射矩阵theta的训练函数：<br><img src="http://ww3.sinaimg.cn/bmiddle/6dd6ca05gw1eros6t3xymj208k01zdfu.jpg" alt=""><br>&emsp;&emsp;至于图2，作者采用了t-SNE[33]的方法来将50-维度的词向量空间映射到2维空间进行可视化。我们可以明显看出，已知类几乎都是聚类在一团的，而未知类是零散分布的。我们可以根据这个来找到哪些是猫，哪些是卡车。</p>
<h3 id="Zero-Shot_Learning_Model：">Zero-Shot Learning Model：</h3><p>&emsp;&emsp;这部分主要是讲如何去做zero-shot classes类的分类器。<br>&emsp;&emsp;首先，我们需要预测p(y|x),y可以分成两部分。一部分是已知类，一部分是未知类。<br><img src="http://ww2.sinaimg.cn/bmiddle/6dd6ca05gw1eros6t6or2j20f901q3yo.jpg" alt=""><br>&emsp;&emsp;V∈s为已知类的先验概率模型，V∈u为未知类的先验概率模型。如果是已知类，则分类器选用softmax回归。如果是未知类，则使用等距高斯分布进行分类。<br>&emsp;&emsp;注意公式里面出现的theta*x表示将测试样本映射到词向量的空间，然后可以得到判断为未知类和已知类的概率，哪个概率高则属于哪一类。如果属于未知类，则将未知类的向量空间与其临近的向量空间进行对比，得到属于cat还是truck。</p>
        
        
        <p class="article-more-link">
          
            <a href="/2015/05/01/post/#more">Read More</a>
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2015/05/01/post/#comments" class="ds-thread-count comments-count-link" data-thread-key="2015/05/01/post/" data-count-type="comments">&nbsp;</a>
	
</div>

</footer>


    </article>







  <nav id="page-nav" class="clearfix">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="顯示側邊欄"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隱藏側邊欄"></a></div>
<aside class="clearfix">

  

  

  <div class="linkslist">
  <p class="asidetitle">友情鏈接</p>
    <ul>
        
          <li>
            
            	<a href="http://sist.shanghaitech.edu.cn/faculty/gaosh/Home.html" target="_blank" title="Computer Vision Group at ShanghaiTech University">Computer Vision Group at ShanghaiTech University</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.shanghaitech.edu.cn/" target="_blank" title="ShanghaiTech Official Website">ShanghaiTech Official Website</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 訂閱</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Xu Tang at ShanghaiTech. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2015 
		
		<a href="/about" target="_blank" title="Xu Tang">Xu Tang</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>




<script type="text/javascript">
  var duoshuoQuery = {short_name:"takecareofbigboss"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 







<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回頂部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
